{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will build a multinomial Naive Bayes algorithm to create a SMS spam filter with 80% accuracy. We will 5,572 messages from a dataset created by the UCI Machine Learning Repository to train and test our filter. \n",
    "\n",
    "Let's start by reading in and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data\n",
    "sms_data = pd.read_csv('SMSSpamCollection', sep='\\t',\n",
    "                      header=None,\n",
    "                      names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding number of rows and columns\n",
    "sms_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding percentage of spam and not-spam (aka ham)\n",
    "\n",
    "sms_data['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes two types of messages: spam and ham (otherwise known as not spam). The ham messages make up 87% of the data and the spam messages make up 13% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can build our spam filter we need to divide the data into a training set and a test set. The data in the training set will be used to develop the spam filter. We'll use the test set to test the accuracy of our training set later in the project.\n",
    "\n",
    "The training set will comprise 80% of the data. We will use the remaining 20% of the data as test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomizing the entire dataset\n",
    "sms_data = sms_data.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "#spliting dataset into two \n",
    "split_80 = int(round(len(sms_data)*.80, 0))\n",
    "\n",
    "train = sms_data[:split_80].reset_index(drop=True)\n",
    "test = sms_data[split_80:].reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: Label, dtype: float64\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#finding percentage of spam and ham for both datasets\n",
    "\n",
    "print(train['Label'].value_counts(normalize=True)*100)\n",
    "print(test['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training and testing datasets match the breakdown of ham (non-spam) and spam messages in the original data. This means our data is representative and we can move forward with building our spam filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can build a naive bayes algorithm to classify messages, we need to clean the messages in training data. We will:\n",
    "- Remove all punctuation from the messages.\n",
    "- Ensure all messages are in lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/nj257d754011vnq1qhd9l_ym0000gn/T/ipykernel_10419/1547852765.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['SMS'] = train['SMS'].str.replace(r\"\\W\",' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes  princess  Are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth   There s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep  by the pretty sculpture\n",
       "1   ham      Yes  princess  Are you going to make me moan \n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent \n",
       "4   ham  I forgot 2 ask ü all smth   There s a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing punctuation from messages\n",
    "\n",
    "train['SMS'] = train['SMS'].str.replace(r\"\\W\",' ')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ham</td>\n",
       "      <td>sorry  i ll call later in meeting any thing re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>ham</td>\n",
       "      <td>y lei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>ham</td>\n",
       "      <td>i dunno they close oredi not    ü v ma fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>spam</td>\n",
       "      <td>123 congratulations   in this week s competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>ham</td>\n",
       "      <td>he needs to stop going to bed and make with th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "4453   ham  sorry  i ll call later in meeting any thing re...\n",
       "1965   ham                                             y lei \n",
       "2508   ham      i dunno they close oredi not    ü v ma fan   \n",
       "3053  spam   123 congratulations   in this week s competit...\n",
       "2682   ham  he needs to stop going to bed and make with th..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting every message to lower case\n",
    "train['SMS'] = train['SMS'].str.lower()\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build our spam filter we need to have a vocabulary, or a list of all unique words in the training set. We will built that now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>ham</td>\n",
       "      <td>[my, sister, got, placed, in, birla, soft, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>ham</td>\n",
       "      <td>[reckon, need, to, be, in, town, by, eightish,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>ham</td>\n",
       "      <td>[also, that, chat, was, awesome, but, don, t, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>ham</td>\n",
       "      <td>[height, of, recycling, read, twice, people, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, can, call, in, lt, gt, min, if, thats, ok]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "2895   ham     [my, sister, got, placed, in, birla, soft, da]\n",
       "2525   ham  [reckon, need, to, be, in, town, by, eightish,...\n",
       "2486   ham  [also, that, chat, was, awesome, but, don, t, ...\n",
       "680    ham  [height, of, recycling, read, twice, people, s...\n",
       "1290   ham     [i, can, call, in, lt, gt, min, if, thats, ok]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting SMS column into list\n",
    "train['SMS'] = train['SMS'].str.split()\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding words from training to vocab list\n",
    "vocabulary = []\n",
    "\n",
    "for row in train['SMS']:\n",
    "    for word in row:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n",
    "            \n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the spam filter, we also need our training set to include a count of words in each message. We'll create a dictionary with word counts for each message and then merge it with the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary \n",
    "\n",
    "word_counts_per_sms = {unique_word: [0] * len(train['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming dictionary into dataframe\n",
    "\n",
    "word_counts_df = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  yep  by  the  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]    1   1    1   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...    0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]    0   0    0   \n",
       "3   ham                                           [havent]    0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0   \n",
       "\n",
       "   pretty  sculpture  yes  princess  are  ...  beauty  hides  secrets  n8  \\\n",
       "0       1          1    0         0    0  ...       0      0        0   0   \n",
       "1       0          0    1         1    1  ...       0      0        0   0   \n",
       "2       0          0    0         0    0  ...       0      0        0   0   \n",
       "3       0          0    0         0    0  ...       0      0        0   0   \n",
       "4       0          0    0         0    0  ...       0      0        0   0   \n",
       "\n",
       "   jewelry  related  trade  arul  bx526  wherre  \n",
       "0        0        0      0     0      0       0  \n",
       "1        0        0      0     0      0       0  \n",
       "2        0        0      0     0      0       0  \n",
       "3        0        0      0     0      0       0  \n",
       "4        0        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the new dataframe to training data\n",
    "\n",
    "train = pd.concat([train, word_counts_df], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our naive bayes algorithm, we'll need to calculate the following constant variables:\n",
    "- The probability of a message being spam\n",
    "- The probability of a message being ham\n",
    "- The number of words in all spam messages\n",
    "- The number of words in all ham messages\n",
    "- The number of words in the vocabulary \n",
    "- An variable for smoothing (which will ensure we don't have any zeros in our probability calculations) equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting train data into spam and ham sets\n",
    "spam_messages = train[train['Label'] == 'spam']\n",
    "ham_messages = train[train['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254\n",
      "0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "#calculating the probability of spam and ham\n",
    "\n",
    "p_spam = len(spam_messages)/len(train)\n",
    "p_ham = len(ham_messages)/len(train)\n",
    "\n",
    "print(p_spam)\n",
    "print(p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15190\n",
      "57237\n"
     ]
    }
   ],
   "source": [
    "#calculating the number of word in spam and ham messages\n",
    "\n",
    "count_of_spam_n = spam_messages['SMS'].apply(len)\n",
    "num_spam = count_of_spam_n.sum()\n",
    "\n",
    "count_of_ham_n = ham_messages['SMS'].apply(len)\n",
    "num_ham = count_of_ham_n.sum()\n",
    "\n",
    "print(num_spam)\n",
    "print(num_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7783\n"
     ]
    }
   ],
   "source": [
    "#calculating n_vocab\n",
    "n_vocab = len(vocabulary)\n",
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initalizing variable alpha\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've established values for our constants, we need to calculate the parameters for our spam filter. We will create dictionaries containing the probability of every word in the vocabulary given both spam and ham. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty dictionary with vocab words\n",
    "para_spam = {unique_word: [0] for unique_word in vocabulary}\n",
    "para_ham = {unique_word: [0] for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through vocabulary to create parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()  \n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (num_spam + alpha*n_vocab)\n",
    "    para_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()   \n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (num_ham + alpha*n_vocab)\n",
    "    para_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying A New Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have both our parameters and constants defined, we can build our naive bayes algorithm. To do this, we will create a function that accepts and classifies new messages according to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in para_spam:\n",
    "            p_spam_given_message *= para_spam[word]\n",
    "        if word in para_ham:\n",
    "            p_ham_given_message *= para_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "#Testing function with spam message\n",
    "message = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "classify(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "#Tesitng function with ham message\n",
    "message = \"Sounds good, Tom, then see u there\"\n",
    "classify(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Filter Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to determine the filter's accuracy by using the filter on the test data. To measure the accuracy, we will tweak the classify function to run on the test data. Then, we will compare the human inputed labels to the results of the classifcation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweaking classification function\n",
    "\n",
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in para_spam:\n",
    "            p_spam_given_message *= para_spam[word]\n",
    "\n",
    "        if word in para_ham:\n",
    "            p_ham_given_message *= para_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dear how is chechi. Did you talk to her</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey mr whats the name of that bill brison book...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>ham</td>\n",
       "      <td>Id have to check but there's only like 1 bowls...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>ham</td>\n",
       "      <td>I got it before the new year cos yetunde said ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm going for bath will msg you next  &amp;lt;#&amp;gt...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS predicted\n",
       "641   ham            Dear how is chechi. Did you talk to her       ham\n",
       "485   ham  Hey mr whats the name of that bill brison book...       ham\n",
       "395   ham  Id have to check but there's only like 1 bowls...       ham\n",
       "608   ham  I got it before the new year cos yetunde said ...       ham\n",
       "712   ham  I'm going for bath will msg you next  &lt;#&gt...       ham"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying updated classifier to testing data\n",
    "\n",
    "test['predicted'] = test['SMS'].apply(classify_test_set)\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is 98.74% accurate.\n"
     ]
    }
   ],
   "source": [
    "#measuring accuracy of filter\n",
    "correct = 0\n",
    "total = len(test)\n",
    "\n",
    "for row in test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "accuracy = round((correct/total)*100,2)\n",
    "print('The filter is {}% accurate.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A filter with 98% accuracy is pretty good. For future iterations, it might be useful to explore the 2% of messages that were incorrectly classified to see if we can make further improvements. Another interesting project might use a similar approach to build a filter for spam text messages rather than spam emails. Unfortunately, spammers are constantly iterating so updating and improving filters is always necessary!\n",
    "\n",
    "Thanks for checking out my project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
